import streamlit as st
# ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥ï¼šfrom streamlit_extras.switch_page_button import switch_page
import base64
import io
import json
import zipfile
from pathlib import Path
from typing import List
import numpy as np
import pandas as pd
import requests
from PIL import Image
from websocket import create_connection, WebSocket
from ultralytics import YOLO
# ... å…¶ä½™ä»£ç ä¿æŒä¸å˜
# å¯é€‰å¯¼å…¥ OpenCVï¼ˆäº‘ç«¯æ²¡æœ‰ GUIï¼Œç”¨ headless è½®å­å³å¯ï¼›å¤±è´¥æ—¶ç¦ç”¨è§†é¢‘ï¼‰
try:
    import cv2  # noqa: F401
    CV2_OK = True
except Exception:
    CV2_OK = False
import skfuzzy as fuzz
from skfuzzy import control as ctrl
import time

# ====================== è¯­è¨€é…ç½® ======================
# åˆå§‹åŒ–è¯­è¨€çŠ¶æ€
if 'language' not in st.session_state:
    st.session_state.language = 'zh'  # é»˜è®¤ä¸­æ–‡

# ç¿»è¯‘å­—å…¸
translations = {
    'zh': {
        'page_title': 'YOLOç—…å®³æ£€æµ‹',
        'header_title': 'é±¼ç±»å¯„ç”Ÿè™«ç—…æ£€æµ‹',
        'header_subtitle': 'å›¾ç‰‡ / æ‰¹é‡ / è§†é¢‘ / æ‘„åƒå¤´ / æ¨¡ç³Šé¢„æµ‹ â€” ä¸€ç«™å¼æ£€æµ‹å°',
        'sidebar_university': 'å®æ³¢å¤§å­¦ Â· ç—…å®³å®éªŒå®¤',
        'sidebar_model': 'ğŸ§  æ¨¡å‹ä¸å‚æ•°',
        'sidebar_model_type': 'æ¨¡å‹ç±»å‹',
        'sidebar_current_model': 'å½“å‰æ¨¡å‹:',
        'tab_image': 'ğŸ–¼ï¸ å›¾ç‰‡æ£€æµ‹',
        'tab_batch': 'ğŸ—‚ï¸ æ‰¹é‡å›¾ç‰‡',
        'tab_video': 'ğŸï¸ è§†é¢‘æ£€æµ‹',
        'tab_camera': 'ğŸ“· æ‘„åƒå¤´æ£€æµ‹',
        'tab_fuzzy': 'ğŸ§® æ¨¡ç³Šé¢„æµ‹',
        'image_original': 'åŸå›¾',
        'image_detection': 'æ£€æµ‹ä¸ç»“æœ',
        'image_upload': 'ä¸Šä¼ å›¾ç‰‡',
        'image_run': 'ğŸš€ å¼€å§‹æ£€æµ‹',
        'image_result': 'æ£€æµ‹ç»“æœ',
        'image_download_excel': 'ä¸‹è½½ Excelï¼ˆæ£€æµ‹è¡¨ï¼‰',
        'image_download_img': 'ä¸‹è½½ æ ‡æ³¨å›¾ç‰‡',
        'batch_upload': 'é€‰æ‹©å¤šå¼ å›¾ç‰‡',
        'batch_run': 'ğŸš€ å¼€å§‹æ‰¹é‡æ£€æµ‹',
        'batch_processing': 'æ¨ç†ä¸­ï¼š',
        'batch_total': 'æ€»æ•°ï¼š',
        'batch_no_results': 'æœªæ£€æµ‹åˆ°ç›®æ ‡ã€‚',
        'batch_download_excel': 'ğŸ“¥ ä¸‹è½½ Excelï¼ˆæ‰¹é‡æ£€æµ‹è¡¨ï¼‰',
        'batch_download_zip': 'ğŸ—œï¸ æ‰“åŒ…ä¸‹è½½ æ ‡æ³¨å›¾ç‰‡ZIP',
        'video_upload': 'ä¸Šä¼ è§†é¢‘',
        'video_run': 'ğŸš€ å¼€å§‹è§†é¢‘æ£€æµ‹',
        'video_disabled': 'å½“å‰äº‘ç«¯ç¯å¢ƒæœªèƒ½åŠ è½½ OpenCVï¼ˆcv2ï¼‰ï¼Œè§†é¢‘å¤„ç†åŠŸèƒ½å·²ç¦ç”¨ã€‚è¯·åœ¨æœ¬åœ°è¿è¡Œæˆ–å®‰è£…æ”¯æŒçš„ OpenCV ç‰ˆæœ¬ã€‚',
        'video_processing': 'æœ¬åœ°è§†é¢‘å¤„ç†...ï¼ˆæŒ‰ CPU é€Ÿåº¦å¯èƒ½è¾ƒæ…¢ï¼‰',
        'video_download': 'ä¸‹è½½å¤„ç†åè§†é¢‘',
        'camera_title': 'ğŸ“· æ‘„åƒå¤´æ£€æµ‹ï¼ˆæ‹ç…§ç‰ˆï¼‰',
        'camera_caption': 'ç‚¹å‡»â€œæ‰“å¼€æ‘„åƒå¤´â€åæ‰æ¸²æŸ“æ‹ç…§æ§ä»¶ï¼›ç‚¹å‡»â€œå…³é—­æ‘„åƒå¤´â€åœæ­¢å¹¶éšè—ã€‚',
        'camera_open': 'ğŸ¬ æ‰“å¼€æ‘„åƒå¤´',
        'camera_close': 'â¹ å…³é—­æ‘„åƒå¤´',
        'camera_not_started': 'æ‘„åƒå¤´æœªå¼€å¯ã€‚ç‚¹å‡»â€œæ‰“å¼€æ‘„åƒå¤´â€å¼€å§‹æ‹ç…§ã€‚',
        'camera_shot': 'ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®æ‹ä¸€å¼ ',
        'camera_detect': 'æ£€æµ‹æ­¤ç…§ç‰‡',
        'fuzzy_title': 'ğŸ§® æ¨¡ç³Šé¢„æµ‹',
        'fuzzy_input': 'è¾“å…¥æŒ‡æ ‡å‚æ•°',
        'fuzzy_day': 'æ—¥é—´è¡Œä¸ºï¼ˆ1~3ï¼‰',
        'fuzzy_night': 'å¤œé—´è¡Œä¸ºï¼ˆ1~3ï¼‰',
        'fuzzy_surface': 'ä½“è¡¨ç‰¹å¾ï¼ˆ1~3ï¼‰',
        'fuzzy_pathogen': 'ç—…åŸç‰¹å¾ï¼ˆ1~3ï¼‰',
        'fuzzy_predict': 'ğŸ§ª é¢„æµ‹',
        'fuzzy_result': 'é£é™©å€¼: {risk_value}ï¼ŒçŠ¶æ€: {risk_status}',
        'Ich': 'å¤šå­å°ç“œè™«ç—…',
        'Tomont': 'åŒ…å›Š',
        'healthy': 'å¥åº·',
        'subhealthy': 'äºšå¥åº·',
        'diseased': 'æ‚£ç—…',
        'category': 'ç±»åˆ«',
        'confidence': 'ç½®ä¿¡åº¦',
        'location': 'ä½ç½®',
        'path': 'è·¯å¾„'
    },
    'en': {
        'page_title': 'YOLO Disease Detection',
        'header_title': 'Fish Parasitic Disease Detection',
        'header_subtitle': 'Image / Batch / Video / Camera / Fuzzy Prediction â€” One-stop Detection Platform',
        'sidebar_university': 'Ningbo University Â· Disease Laboratory',
        'sidebar_model': 'ğŸ§  Model & Parameters',
        'sidebar_model_type': 'Model Type',
        'sidebar_current_model': 'Current Model:',
        'tab_image': 'ğŸ–¼ï¸ Image Detection',
        'tab_batch': 'ğŸ—‚ï¸ Batch Images',
        'tab_video': 'ğŸï¸ Video Detection',
        'tab_camera': 'ğŸ“· Camera Detection',
        'tab_fuzzy': 'ğŸ§® Fuzzy Prediction',
        'image_original': 'Original Image',
        'image_detection': 'Detection & Results',
        'image_upload': 'Upload Image',
        'image_run': 'ğŸš€ Start Detection',
        'image_result': 'Detection Result',
        'image_download_excel': 'Download Excel (Detection Table)',
        'image_download_img': 'Download Annotated Image',
        'batch_upload': 'Select Multiple Images',
        'batch_run': 'ğŸš€ Start Batch Detection',
        'batch_processing': 'Processing: ',
        'batch_total': 'Total: ',
        'batch_no_results': 'No targets detected.',
        'batch_download_excel': 'ğŸ“¥ Download Excel (Batch Detection)',
        'batch_download_zip': 'ğŸ—œï¸ Download Annotated Images (ZIP)',
        'video_upload': 'Upload Video',
        'video_run': 'ğŸš€ Start Video Detection',
        'video_disabled': 'OpenCV (cv2) not loaded in current cloud environment. Video processing disabled. Please run locally or install supported OpenCV version.',
        'video_processing': 'Local video processing... (May be slow depending on CPU)',
        'video_download': 'Download Processed Video',
        'camera_title': 'ğŸ“· Camera Detection (Photo Mode)',
        'camera_caption': 'Camera widget loads only after clicking "Open Camera"; click "Close Camera" to stop and hide.',
        'camera_open': 'ğŸ¬ Open Camera',
        'camera_close': 'â¹ Close Camera',
        'camera_not_started': 'Camera not started. Click "Open Camera" to begin.',
        'camera_shot': 'Click button below to take photo',
        'camera_detect': 'Detect This Photo',
        'fuzzy_title': 'ğŸ§® Fuzzy Prediction',
        'fuzzy_input': 'Input Indicator Parameters',
        'fuzzy_day': 'Day Behavior (1~3)',
        'fuzzy_night': 'Night Behavior (1~3)',
        'fuzzy_surface': 'Surface Features (1~3)',
        'fuzzy_pathogen': 'Pathogen Features (1~3)',
        'fuzzy_predict': 'ğŸ§ª Predict',
        'fuzzy_result': 'Risk Value: {risk_value}, Status: {risk_status}',
        'Ich': 'Ichthyophthirius Disease',
        'Tomont': 'Tomont',
        'healthy': 'Healthy',
        'subhealthy': 'Subhealthy',
        'diseased': 'Diseased',
        'category': 'Category',
        'confidence': 'Confidence',
        'location': 'Location',
        'path': 'Path'
    }
}

# è·å–å½“å‰è¯­è¨€ç¿»è¯‘
def t(key):
    return translations[st.session_state.language].get(key, key)

# ====================== é¡µé¢é…ç½® ======================
st.set_page_config(page_title=t('page_title'), page_icon="ğŸ§ª", layout="wide")

# ====================== åŸæœ‰ä»£ç ï¼ˆä¿®æ”¹æ–‡æœ¬ä¸ºç¿»è¯‘è°ƒç”¨ï¼‰ ======================

# ä»¥å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•ä¸ºåŸºå‡†
BASE_DIR = Path(__file__).parent
WEIGHTS = BASE_DIR / "best.pt"  # Ichæ¨¡å‹
TOMONT_WEIGHTS = BASE_DIR / "tomont.best.pt"  # æ–°å¢Tomontæ¨¡å‹è·¯å¾„
IMG_DIR = BASE_DIR / "img"
MODEL_PATHS = {"Ich": str(WEIGHTS), "Tomont": str(TOMONT_WEIGHTS)}  # ç§»é™¤Lycï¼Œåˆ†åˆ«å¯¹åº”ä¸åŒæ¨¡å‹
DEFAULT_CONF = 0.6  # é»˜è®¤ç½®ä¿¡åº¦

# ä½ çš„æ¨¡å‹æ¸…å•ï¼ˆå¯æ‰©å±•å¤šä¸ªï¼‰
# ========= æœ¬åœ°æ¨¡å‹ä¸å·¥å…· =========

# å¦‚æœä¸‰ä¸ªç±»åˆ«å…±ç”¨åŒä¸€æƒé‡ï¼Œå…ˆéƒ½æŒ‡å‘ best.ptï¼›å°†æ¥æœ‰ä¸åŒæƒé‡å†æ”¹è¿™é‡Œçš„è·¯å¾„å³å¯
# MODEL_PATHS = {"Lyc": "best.pt", "Ich": "best.pt", "Tomont": "tomont.best.pt"}

@st.cache_resource
def load_models():
    models = {}
    for k, p in MODEL_PATHS.items():
        if not Path(p).exists():
            st.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{p}ï¼ˆ{k}æ¨¡å‹ï¼‰")  # æ–°å¢ï¼šéªŒè¯æ–‡ä»¶å­˜åœ¨
        models[k] = YOLO(p)
        st.success(f"æˆåŠŸåŠ è½½æ¨¡å‹ï¼š{k} -> {p}")  # æ–°å¢ï¼šæ‰“å°åŠ è½½æ—¥å¿—
    return models

MODELS = load_models()

def detections_to_df(res) -> pd.DataFrame:
    """
    ç»Ÿä¸€è½¬è¡¨ï¼š
    - Ultralytics Resultsï¼ˆå•å¸§ï¼‰å¯¹è±¡ï¼šä» res.boxes æ cls/conf/xyxyã€‚
    - è€æ¥å£ list[dict]ï¼šç»§ç»­ä½¿ç”¨ d.get(...) å…¼å®¹ã€‚
    """
    # A) Ultralytics Results å¯¹è±¡
    if hasattr(res, "boxes") and hasattr(res, "names"):
        rows = []
        names = getattr(res, "names", {}) or {}
        boxes = getattr(res, "boxes", None)

        if boxes is not None and len(boxes) > 0:
            cls_np  = boxes.cls.detach().cpu().numpy().astype(int)
            conf_np = boxes.conf.detach().cpu().numpy()
            xyxy_np = boxes.xyxy.detach().cpu().numpy()
            for i in range(len(cls_np)):
                rows.append({
                    t("category"): names.get(int(cls_np[i]), str(int(cls_np[i]))),
                    t("confidence"): float(conf_np[i]),
                    t("location"): [float(x) for x in xyxy_np[i].tolist()],
                })
        return pd.DataFrame(rows)

    # B) è€çš„ list[dict] ç»“æ„ï¼ˆä¿æŒå…¼å®¹ï¼Œå¦‚æœä½ ä¹‹åä¸ç”¨ï¼Œå¯ä»¥åˆ æ‰è¿™æ®µï¼‰
    if isinstance(res, list):
        rows = []
        for d in res or []:
            rows.append({
                t("category"): d.get("category") or d.get("class_name") or d.get("name") or d.get("cls"),
                t("confidence"): d.get("conf") or d.get("confidence"),
                t("location"): d.get("location") or d.get("bbox") or d.get("xyxy"),
                t("path"): d.get("path"),
            })
        return pd.DataFrame(rows)

    # å·²æ˜¯ DataFrame ç›´æ¥è¿”å›ï¼›å…¶å®ƒç±»å‹ç»™ç©ºè¡¨
    if isinstance(res, pd.DataFrame):
        return res

    return pd.DataFrame()

def predict_on_image(img_input, model_key: str, conf: float | None = None):
    # ç»Ÿä¸€è½¬ PIL
    if isinstance(img_input, (bytes, bytearray)):
        pil_img = Image.open(io.BytesIO(img_input)).convert("RGB")
    elif isinstance(img_input, Image.Image):
        pil_img = img_input.convert("RGB")
    elif isinstance(img_input, (str, Path)):
        pil_img = Image.open(img_input).convert("RGB")
    elif isinstance(img_input, np.ndarray):
        if img_input.ndim == 2:
            pil_img = Image.fromarray(img_input)  # ç°åº¦
        elif img_input.ndim == 3:
            if CV2_OK:
                pil_img = Image.fromarray(cv2.cvtColor(img_input, cv2.COLOR_BGR2RGB))
            else:
                # å‡è®¾ BGR -> RGBï¼ˆæ—  cv2 æ—¶ç”¨é€šé“åè½¬ï¼‰
                pil_img = Image.fromarray(img_input[..., ::-1])
        else:
            raise TypeError(f"Unsupported numpy shape: {img_input.shape}")
    else:
        raise TypeError(f"Unsupported type: {type(img_input)}")

    # æ¨ç†
    c = float(conf) if conf is not None else DEFAULT_CONF
    # r = MODELS[model_key].predict(source=pil_img, conf=float(conf), imgsz=640, verbose=False)[0]
    r = MODELS[model_key].predict(source=pil_img, conf=c, imgsz=640, verbose=False)[0]

    # å¯è§†åŒ–ï¼ˆUltralytics è¿”å› BGR ndarrayï¼‰
    im_bgr = r.plot()
    im_rgb = im_bgr[..., ::-1]  # ä¸ä¾èµ– cv2
    vis_pil = Image.fromarray(im_rgb)

    df = detections_to_df(r)
    return vis_pil, df

def process_video(video_bytes: bytes, model_key: str, conf: float | None = None, max_frames: int | None = None) -> Path:
    if not CV2_OK:
        raise RuntimeError(t("video_disabled"))
    """é€å¸§æ¨ç†å¹¶è¾“å‡º mp4ï¼Œè¿”å›è¾“å‡ºè§†é¢‘è·¯å¾„"""
    in_path = Path("input_tmp.mp4"); in_path.write_bytes(video_bytes)
    cap = cv2.VideoCapture(str(in_path))
    if not cap.isOpened(): raise RuntimeError("æ— æ³•è¯»å–è§†é¢‘" if st.session_state.language == 'zh' else "Cannot read video")

    fps = cap.get(cv2.CAP_PROP_FPS) or 25
    w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    out_path = Path(f"processed_{int(time.time())}.mp4")
    vw = cv2.VideoWriter(str(out_path), cv2.VideoWriter_fourcc(*"mp4v"), fps, (w, h))

    i = 0
    while True:
        ok, frame = cap.read()
        if not ok: break
        i += 1
        if max_frames and i > max_frames: break
        c = float(conf) if conf is not None else DEFAULT_CONF
        # r = MODELS[model_key].predict(source=frame, conf=float(conf), imgsz=640, verbose=False)[0]
        r = MODELS[model_key].predict(source=frame, conf=c, imgsz=640, verbose=False)[0]
        vw.write(r.plot())

    cap.release(); vw.release()
    return out_path

def save_table_to_excel(df: pd.DataFrame, filename: str) -> Path:
    out = Path(filename).with_suffix(".xlsx")
    with pd.ExcelWriter(out, engine="xlsxwriter") as w:
        df.to_excel(w, sheet_name="detections" if st.session_state.language == 'zh' else "Detections", index=False)
    return out

def zip_files(files: list[Path], out_zip: Path) -> Path:
    with zipfile.ZipFile(out_zip, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        for f in files:
            if f.exists(): zf.write(f, arcname=f.name)
    return out_zip

# ========= æ¨¡ç³Šé¢„æµ‹ï¼ˆå’Œä½ åç«¯ä¸€è‡´çš„ scikit-fuzzy è§„åˆ™ï¼‰ =========
@st.cache_resource
def build_fuzzy_sim():
    day = ctrl.Antecedent(np.arange(1, 4.1, 0.1), 'day')
    night = ctrl.Antecedent(np.arange(1, 4.1, 0.1), 'night')
    surf = ctrl.Antecedent(np.arange(1, 4.1, 0.1), 'surf')
    patho = ctrl.Antecedent(np.arange(1, 4.1, 0.1), 'patho')
    risk = ctrl.Consequent(np.arange(0, 4.1, 0.1), 'risk')

    for b in [day, night]:
        b['healthy'] = fuzz.trimf(b.universe, [1, 1, 1.5])
        b['subhealthy'] = fuzz.trimf(b.universe, [1.5, 2, 2.5])
        b['diseased'] = fuzz.trimf(b.universe, [2.5, 3, 4])

    surf['healthy'] = fuzz.trimf(surf.universe, [1, 1, 2])
    surf['diseased'] = fuzz.trimf(surf.universe, [2, 3, 4])
    patho['absent'] = fuzz.trimf(patho.universe, [1, 1, 2])
    patho['present'] = fuzz.trimf(patho.universe, [2, 3, 4])

    risk['health'] = fuzz.trimf(risk.universe, [0, 1, 1.5])
    risk['subhealth'] = fuzz.trimf(risk.universe, [1.5, 2, 2.5])
    risk['diseased'] = fuzz.trimf(risk.universe, [2.5, 3, 4])
    risk.defuzzify_method = 'centroid'

    rules = [
        ctrl.Rule(day['subhealthy'] & night['diseased'] & surf['healthy'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['healthy'] & night['healthy'] & surf['healthy'] & patho['absent'], risk['health']),
        ctrl.Rule(day['diseased'] | night['diseased'], risk['diseased']),
        ctrl.Rule(day['subhealthy'] | night['subhealthy'], risk['subhealth']),
        ctrl.Rule(surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(surf['healthy'] & patho['absent'], risk['health']),
        ctrl.Rule(day['healthy'] & night['subhealthy'] & surf['healthy'] & patho['present'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['healthy'] & surf['healthy'] & patho['present'], risk['subhealth']),
        ctrl.Rule(day['healthy'] & night['healthy'] & surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['healthy'] & night['healthy'] & surf['healthy'] & patho['present'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['subhealthy'] & surf['healthy'] & patho['absent'], risk['health']),
        ctrl.Rule(day['subhealthy'] & night['subhealthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['diseased'] & surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['diseased'] & night['subhealthy'] & surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['subhealthy'] & night['subhealthy'] & surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['healthy'] & night['subhealthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['healthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['subhealthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['healthy'] & night['healthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['diseased'] & night['diseased'] & surf['healthy'] & patho['absent'], risk['diseased']),
        ctrl.Rule(day['diseased'] & night['diseased'] & surf['diseased'] & patho['absent'], risk['diseased']),
        ctrl.Rule(day['diseased'] & night['diseased'] & surf['healthy'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['diseased'] & night['diseased'] & surf['diseased'] & patho['present'], risk['diseased']),
    ]
    for r in rules: r.weight = 1.0
    rules[4].weight = 2; rules[5].weight = 2

    return ctrl.ControlSystemSimulation(ctrl.ControlSystem(rules))

def fuzzy_predict(day_val: float, night_val: float, surf_val: float, patho_val: float) -> dict:
    sim = build_fuzzy_sim()
    sim.input['day'] = day_val
    sim.input['night'] = night_val
    sim.input['surf'] = surf_val
    sim.input['patho'] = patho_val
    sim.compute()
    v = float(sim.output['risk'])
    if st.session_state.language == 'zh':
        status = "å¥åº·" if v < 1.5 else ("äºšå¥åº·" if v < 2.5 else "æ‚£ç—…")
    else:
        status = t("healthy") if v < 1.5 else (t("subhealthy") if v < 2.5 else t("diseased"))
    return {"risk_value": round(v, 1), "risk_status": status}

# ========================= å…¨å±€è®¾ç½® & ä¸»é¢˜æ‰©å±• =========================

# ç»Ÿä¸€çš„ CSSï¼šå¯¼èˆªæ¡ / å¡ç‰‡ / æ ‡ç­¾ / è¡¨æ ¼ / æŒ‰é’®
st.markdown("""
<style>
.app-header {
  background: linear-gradient(90deg, #4F46E5 0%, #7C3AED 100%);
  color: white; border-radius: 16px; padding: 16px 20px; margin-bottom: 12px;
  display:flex; align-items:center; gap:14px;
}
.app-title { font-size: 22px; font-weight: 700; letter-spacing:.3px; }
.app-subtitle { opacity:.9; font-size: 13px; }

.note {
  background:#EEF2FF; border:1px solid #E0E7FF; color:#3730A3;
  border-radius: 12px; padding: 10px 12px; margin: 6px 0 16px 0; font-size:13px;
}

.card {
  background: var(--secondary-bg, #F6F7FB);
  border: 1px solid #E5E7EB;
  border-radius: 14px;
  padding: 14px;
  margin-bottom: 12px;
}

:root { --secondary-bg: #F6F7FB; }
[data-base-theme="light"] :root { --secondary-bg: #F6F7FB; }
[data-base-theme="dark"]  :root { --secondary-bg: #111827; }

[data-testid="stDataFrame"] { border-radius: 12px; overflow:hidden; }

.stButton>button { border-radius: 10px; }
.block-container { padding-top: 0.6rem; padding-bottom: 1rem; }

.badge {
  display: inline-flex; align-items: center; gap: 6px;
  background: #EEF2FF; color:#3730A3; border:1px solid #E0E7FF;
  padding: 4px 8px; border-radius: 999px; font-size: 12px; font-weight:600;
}

/* è¯­è¨€åˆ‡æ¢æŒ‰é’®æ ·å¼ */
.lang-switch {
  position: fixed;
  top: 20px;
  right: 20px;
  z-index: 999;
}
</style>
""", unsafe_allow_html=True)

# éšè— Streamlit é¡¶éƒ¨æ ï¼ˆæ–¹æ¡ˆ Bï¼‰
st.markdown("""
<style>
header[data-testid="stHeader"] {visibility: hidden;}
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
[data-testid="stAppViewContainer"] .main .block-container { padding-top: 0.8rem !important; }
.app-header { margin-top: 4px; }
</style>
""", unsafe_allow_html=True)

# åªéšè—æˆ‘ä»¬è‡ªå®šä¹‰çš„æœåŠ¡é…ç½®å®¹å™¨ï¼ˆæ›´ç¨³ï¼‰
st.markdown("""
<style>
#svc-config { display: none !important; }  /* â† è¢«éšè—çš„å®¹å™¨ */
</style>
""", unsafe_allow_html=True)

# è¯­è¨€åˆ‡æ¢æŒ‰é’®
with st.sidebar:
    lang_col1, lang_col2 = st.columns(2)
    with lang_col1:
        if st.button('ä¸­æ–‡', use_container_width=True):
            st.session_state.language = 'zh'
            st.rerun()
    with lang_col2:
        if st.button('English', use_container_width=True):
            st.session_state.language = 'en'
            st.rerun()

# é¡¶éƒ¨å¯¼èˆªæ¡
st.markdown(f"""
<style>
/* ===== é¡¶éƒ¨æ¨ªå¹…æ•´ä½“æ ·å¼ ===== */
.app-header {{
  background: linear-gradient(90deg, #4F46E5 0%, #7C3AED 100%);
  color: white;
  border-radius: 14px;     /* åœ†è§’ç¨å¾®å°ä¸€äº› */
  padding: 14px 18px;      /* åŸæ¥ 26x20ï¼Œç¼©å°åˆ°æ›´ç´§å‡‘ */
  margin-bottom: 14px;
  text-align: center;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
}}


/* ===== å›¾æ ‡ä¸æ ‡é¢˜ä¸€è¡Œ ===== */
.app-title-row {{
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 12px;  /* å›¾æ ‡ä¸æ ‡é¢˜é—´è· */
  margin-bottom: 8px;
}}

.app-icon {{
  font-size: 42px;
}}

.app-title {{
  font-size: 36px;
  font-weight: 800;
  letter-spacing: 1px;
}}

.app-subtitle {{
  font-size: 20px;
  opacity: 0.95;
}}
</style>

<div class="app-header">
  <div class="app-title-row">
    <div class="app-icon">ğŸ§ª</div>
    <div class="app-title">{t('header_title')}</div>
  </div>
  <div class="app-subtitle">{t('header_subtitle')}</div>
</div>
""", unsafe_allow_html=True)

# ------------------------- ä¾§è¾¹æ  -------------------------
with st.sidebar:
    # ======= è¿™é‡Œæ”¾ä½ çš„æ ¡å¾½ / é¡¹ç›®ç®€ä»‹ï¼ˆä¼šæ˜¾ç¤ºï¼‰=======
    # æŠŠ school_logo.png æ”¾åˆ°åŒçº§ç›®å½•åå–æ¶ˆä¸‹ä¸€è¡Œæ³¨é‡Šå³å¯ï¼š
    # st.image("school_logo.png", use_container_width=True)
    st.markdown(f"""
    ### ğŸ“ {t('sidebar_university')}
    """)
    # st.image("img/img1.png", width='stretch')
    # st.image(str(IMG_DIR / "img1.png"), use_column_width=True)

    # st.markdown("---")
    # ======= ä»¥ä¸‹ä¸ºâ€œæœåŠ¡é…ç½® + æ¨¡å‹å‚æ•°â€åŒºåŸŸï¼Œå¤–é¢åŒ…äº†ä¸€ä¸ªå®¹å™¨ï¼Œå·²é€šè¿‡ CSS éšè— =======
    st.markdown('<div id="svc-config">', unsafe_allow_html=True)

    # st.header("âš™ï¸ æœåŠ¡é…ç½®")
    # base_url = st.text_input("åç«¯åœ°å€", value="http://localhost:8080",
    #                          help="ç¤ºä¾‹ï¼šhttp://127.0.0.1:8000 æˆ– http://localhost:8080")
    # default_ws = base_url.replace("http://", "ws://").replace("https://", "wss://")
    # ws_url_override = st.text_input("WebSocket åŸºåœ°å€ï¼ˆå¯é€‰ï¼‰", value=default_ws,
    #                                 help="é€šå¸¸ä¸åç«¯ä¸€è‡´ï¼Œè‡ªåŠ¨ä»åç«¯åœ°å€æ¨å¯¼")

    base_url = "http://localhost:8080"
    ws_url_override = base_url.replace("http://", "ws://").replace("https://", "wss://")
    st.divider()
    st.header(t('sidebar_model'))
    model_options = {"Ich": t('Ich'), "Tomont": t('Tomont')}
    model_value = st.selectbox(t('sidebar_model_type'), options=list(model_options.keys()),
                               format_func=lambda x: f"{x}ï¼ˆ{model_options[x]}ï¼‰")
    # conf = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.05, 1.0, 0.6, 0.05)
    st.markdown(f"<span class='badge'>{t('sidebar_current_model')} <b>{model_value}</b></span>", unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)  # â† ç»“æŸéšè—å®¹å™¨

# # é¡¶éƒ¨æç¤ºæ¡
# st.markdown("""
# <div class="note">
# ğŸ’¡ å°æç¤ºï¼šå·¦ä¾§å¯å±•ç¤ºæ ¡å¾½ä¸é¡¹ç›®ç®€ä»‹ï¼›å†…éƒ¨â€œæœåŠ¡é…ç½®/æ¨¡å‹å‚æ•°â€å·²éšè—ä½†ä»ç”Ÿæ•ˆã€‚å¦‚éœ€ä¸´æ—¶æ˜¾ç¤ºï¼Œå¯æŠŠ CSS ä¸­çš„ #svc-config éšè—è§„åˆ™å»æ‰ã€‚
# </div>
# """, unsafe_allow_html=True)

# ========================= å·¥å…·å‡½æ•° =========================
def b64_to_pil(maybe_b64):
    """å…¼å®¹çº¯ base64 / data URL / bytesï¼›URL è¿”å› None äº¤ç”± st.image(url)ã€‚"""
    import io, base64
    from PIL import Image
    if maybe_b64 is None:
        raise ValueError("empty image input" if st.session_state.language == 'en' else "ç©ºå›¾ç‰‡è¾“å…¥")
    if isinstance(maybe_b64, str) and maybe_b64.strip().lower().startswith(("http://", "https://")):
        return None
    if isinstance(maybe_b64, (bytes, bytearray)):
        return Image.open(io.BytesIO(maybe_b64)).convert("RGB")
    if isinstance(maybe_b64, str):
        s = maybe_b64.strip()
        if s.lower().startswith("data:image"):
            parts = s.split(",", 1)
            s = parts[1] if len(parts) > 1 else ""
        s = s.replace("\n", "").replace("\r", "").replace(" ", "")
        missing = len(s) % 4
        if missing:
            s += "=" * (4 - missing)
        raw = base64.b64decode(s, validate=False)
        return Image.open(io.BytesIO(raw)).convert("RGB")
    raise TypeError(f"unsupported type for image: {type(maybe_b64)}" if st.session_state.language == 'en' else f"ä¸æ”¯æŒçš„å›¾ç‰‡ç±»å‹: {type(maybe_b64)}")

def ensure_ok(resp: requests.Response):
    if not resp.ok:
        try:
            detail = resp.json()
        except Exception:
            detail = resp.text
        raise RuntimeError(f"HTTP {resp.status_code}: {detail}")

def save_table_to_excel(df: pd.DataFrame, filename: str) -> Path:
    out = Path(filename).with_suffix(".xlsx")
    with pd.ExcelWriter(out, engine="xlsxwriter") as writer:
        df.to_excel(writer, sheet_name="detections" if st.session_state.language == 'en' else "æ£€æµ‹ç»“æœ", index=False)
    return out

def zip_files(files: List[Path], out_zip: Path) -> Path:
    with zipfile.ZipFile(out_zip, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        for f in files:
            if f.exists():
                zf.write(f, arcname=f.name)
    return out_zip

# ========================= æ ‡ç­¾é¡µ =========================
tab_img, tab_folder, tab_video, tab_camera, tab_fuzzy = st.tabs([
    t('tab_image'), 
    t('tab_batch'), 
    t('tab_video'), 
    t('tab_camera'), 
    t('tab_fuzzy')
])

# -------------------------------- 1) å›¾ç‰‡æ£€æµ‹ --------------------------------
with tab_img:
    st.markdown(f"#### {t('tab_image')}")
    col1, col2 = st.columns(2)

    # å·¦ä¾§ï¼šåŸå›¾
    with col1:
        st.markdown(f"<div class='card'><b>{t('image_original')}</b></div>", unsafe_allow_html=True)
        img_file = st.file_uploader(t('image_upload'), type=["jpg","jpeg","png","bmp","webp"], key="single_img_main")
        if img_file:
            st.image(Image.open(img_file), caption=t('image_original'), use_column_width=True)

    # å³ä¾§ï¼šæ£€æµ‹ä¸ç»“æœ
    with col2:
        st.markdown(f"<div class='card'><b>{t('image_detection')}</b></div>", unsafe_allow_html=True)
        run_single = st.button(t('image_run'), type="primary", use_container_width=True, disabled=img_file is None)

        if run_single and img_file:
            files = {"file": (img_file.name, img_file.getvalue(), img_file.type or "image/jpeg")}
            data = {"model_type": model_value}
            # params = {"conf": conf}

            with st.spinner("æœ¬åœ°æ¨¡å‹æ¨ç†ä¸­..." if st.session_state.language == 'zh' else "Local model inferencing..."):
                # det_img, df = predict_on_image(img_file.getvalue(), model_value, conf)
                det_img, df = predict_on_image(img_file.getvalue(), model_value)

            st.image(det_img, caption=t('image_result'), use_column_width=True)
            if not df.empty:
                st.dataframe(df, use_container_width=True)
                c1, c2 = st.columns(2)
                with c1:
                    if st.button(t('image_download_excel'), use_container_width=True):
                        xlsx_path = save_table_to_excel(df, "image_detect_result.xlsx")
                        st.download_button(t('image_download_excel'), data=open(xlsx_path, "rb").read(),
                                           file_name=xlsx_path.name,
                                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
                with c2:
                    if st.button(t('image_download_img'), use_container_width=True):
                        bio = io.BytesIO();
                        det_img.save(bio, format="JPEG")
                        st.download_button(t('image_download_img'), data=bio.getvalue(), file_name="image_detect_result.jpg",
                                           mime="image/jpeg")

# ----------------------------- 2) æ‰¹é‡å›¾ç‰‡æ£€æµ‹ -----------------------------
with tab_folder:
    st.markdown(f"#### {t('tab_batch')}")
    files = st.file_uploader(
        t('batch_upload'),
        type=["jpg", "jpeg", "png", "bmp", "webp"],
        accept_multiple_files=True,
        key="multi_imgs",
    )
    go = st.button(t('batch_run'), type="primary", disabled=not files)

    if go and files:
        all_tables: List[pd.DataFrame] = []
        out_imgs: List[Path] = []

        progress = st.progress(0)
        status = st.empty()

        total = len(files)
        for i, f in enumerate(files, start=1):
            status.info(f"{t('batch_processing')}{f.name} ({i}/{total})")
            with st.spinner(f"{t('batch_processing')}{f.name}"):
                # det_img, df = predict_on_image(f.getvalue(), model_value, conf)
                det_img, df = predict_on_image(f.getvalue(), model_value)

                # ç»“æœè¡¨
                if not df.empty:
                    df[t("path")] = f.name
                    all_tables.append(df)

                # ä¿å­˜æ ‡æ³¨å›¾åˆ°æœ¬åœ°ï¼Œç¨åæ‰“åŒ…ä¸‹è½½
                out_path = Path(f"{Path(f.name).stem}_detect.jpg")
                det_img.save(out_path)
                out_imgs.append(out_path)

            progress.progress(i / total)

        # æ±‡æ€»è¡¨æ ¼
        df_all = pd.concat(all_tables, ignore_index=True) if all_tables else pd.DataFrame()
        if not df_all.empty:
            st.dataframe(df_all, use_container_width=True)
            xlsx_path = save_table_to_excel(df_all, "batch_detect.xlsx")
            st.download_button(
                t('batch_download_excel'),
                data=open(xlsx_path, "rb").read(),
                file_name=xlsx_path.name,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
            )
        else:
            st.info(t('batch_no_results'))

        # æ‰“åŒ…æ ‡æ³¨å›¾
        if out_imgs:
            zpath = zip_files(out_imgs, Path("batch_detect_images.zip"))
            st.download_button(
                t('batch_download_zip'),
                data=open(zpath, "rb").read(),
                file_name=zpath.name,
                mime="application/zip",
                use_container_width=True,
            )

        status.empty()
        progress.empty()

# -------------------------------- 3) è§†é¢‘æ£€æµ‹ --------------------------------
with tab_video:
    st.markdown(f"#### {t('tab_video')}")
    vid_file = st.file_uploader(
        t('video_upload'), type=["mp4", "mov", "avi", "mkv"], key="video_file"
    )
    # run_vid = st.button("ğŸš€ å¼€å§‹è§†é¢‘æ£€æµ‹", type="primary", disabled=vid_file is None)
    run_vid = st.button(t('video_run'), type="primary", disabled=(vid_file is None or not CV2_OK))
    if not CV2_OK:
        st.warning(t('video_disabled'))

    if run_vid and vid_file:
        with st.spinner(t('video_processing')):
            # æœ¬åœ°é€å¸§æ¨ç†å¹¶å¯¼å‡ºå¤„ç†åçš„è§†é¢‘
            out_path = process_video(
                # vid_file.getvalue(), model_value, conf, max_frames=None
                vid_file.getvalue(), model_value, max_frames=None
            )
        st.video(str(out_path))
        st.download_button(
            t('video_download'),
            data=open(out_path, "rb").read(),
            file_name=out_path.name,
            mime="video/mp4",
        )

# -------------------------- 4) æ‘„åƒå¤´æ£€æµ‹ï¼ˆæ‹ç…§ç‰ˆï¼Œæ‰‹åŠ¨å¼€å¯ï¼‰ --------------------------
with tab_camera:
    st.markdown(f"#### {t('camera_title')}")
    st.caption(t('camera_caption'))

    # åˆå§‹åŒ–çŠ¶æ€
    if "cam_on" not in st.session_state:
        st.session_state.cam_on = False

    col_a, col_b = st.columns(2)
    if not st.session_state.cam_on:
        if col_a.button(t('camera_open'), type="primary"):
            st.session_state.cam_on = True
            st.rerun()
        col_b.button(t('camera_close'), disabled=True)
        st.info(t('camera_not_started'))
    else:
        if col_b.button(t('camera_close'), type="secondary"):
            st.session_state.cam_on = False
            st.rerun()
        col_a.button(t('camera_open'), disabled=True)

        # åªæœ‰åœ¨ cam_on=True æ—¶æ‰æ¸²æŸ“ camera_inputï¼Œé¿å…é¡µé¢åŠ è½½å°±è§¦å‘æƒé™ä¸å–æµ
        snap = st.camera_input(t('camera_shot'), key="cam_shot")

        go = st.button(t('camera_detect'), type="primary", disabled=(snap is None))
        if go and snap is not None:
            with st.spinner("æœ¬åœ°æ¨¡å‹æ¨ç†ä¸­..." if st.session_state.language == 'zh' else "Local model inferencing..."):
                # det_img, df = predict_on_image(snap.getvalue(), model_value, conf)
                det_img, df = predict_on_image(snap.getvalue(), model_value)
            st.image(det_img, caption=t('image_result'), use_column_width=True)
            if not df.empty:
                st.dataframe(df, use_container_width=True)

# -------------------------------- 5) æ¨¡ç³Šé¢„æµ‹ --------------------------------
with tab_fuzzy:
    st.markdown(f"#### {t('fuzzy_title')}")
    st.markdown(f"<div class='card'><b>{t('fuzzy_input')}</b></div>", unsafe_allow_html=True)

    c1, c2 = st.columns(2)
    with c1:
        day_behavior   = st.number_input(t('fuzzy_day'),  min_value=1.0, max_value=3.0, value=3.0, step=1.0)
        night_behavior = st.number_input(t('fuzzy_night'),  min_value=1.0, max_value=3.0, value=1.0, step=1.0)
    with c2:
        surface_features = st.number_input(t('fuzzy_surface'), min_value=1.0, max_value=3.0, value=3.0, step=1.0)
        pathogen         = st.number_input(t('fuzzy_pathogen'), min_value=1.0, max_value=3.0, value=3.0, step=1.0)

    if st.button(t('fuzzy_predict'), type="primary"):
        r = fuzzy_predict(day_behavior, night_behavior, surface_features, pathogen)
        st.success(t('fuzzy_result').format(risk_value=r['risk_value'], risk_status=r['risk_status']))




