import streamlit as st
import base64
import io
import json
import zipfile
from pathlib import Path
from typing import List
import numpy as np
import pandas as pd
import requests
from PIL import Image
from websocket import create_connection, WebSocket
from ultralytics import YOLO
import math  # æ–°å¢ï¼šç”¨äºè®¡ç®—æ¬§æ°è·ç¦»
try:
    import cv2  # noqa: F401
    CV2_OK = True
except Exception:
    CV2_OK = False
import skfuzzy as fuzz
from skfuzzy import control as ctrl
import time

# ====================== è¯­è¨€é…ç½®ï¼ˆæ–°å¢è½¨è¿¹è·Ÿè¸ªç¿»è¯‘ï¼‰ ======================
if 'language' not in st.session_state:
    st.session_state.language = 'zh'  # é»˜è®¤ä¸­æ–‡

# ç¿»è¯‘å­—å…¸ï¼ˆæ–°å¢è½¨è¿¹è·Ÿè¸ªç›¸å…³å­—æ®µï¼‰
translations = {
    'zh': {
        # åŸæœ‰ç¿»è¯‘ä¿ç•™ï¼Œæ–°å¢ä»¥ä¸‹å­—æ®µ
        'tab_tracking': 'ğŸ“ è½¨è¿¹è·Ÿè¸ª',
        'tracking_title': 'é‡‘é±¼è¿åŠ¨è½¨è¿¹åˆ†æ',
        'tracking_upload': 'ä¸Šä¼ è§†é¢‘æ–‡ä»¶',
        'tracking_run': 'ğŸš€ å¼€å§‹è½¨è¿¹åˆ†æ',
        'tracking_processing': 'æ­£åœ¨åˆ†æè§†é¢‘è½¨è¿¹...',
        'total_distance': 'æ€»è·¯ç¨‹ï¼ˆåƒç´ ï¼‰',
        'average_speed': 'å¹³å‡è¿åŠ¨é€Ÿåº¦ï¼ˆåƒç´ /ç§’ï¼‰',
        'video_duration': 'è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰',
        'total_frames': 'æ€»å¸§æ•°',
        'no_fish_detected': 'æœªæ£€æµ‹åˆ°é‡‘é±¼ï¼Œæ— æ³•è®¡ç®—è½¨è¿¹æ•°æ®',
        # åŸæœ‰ç¿»è¯‘
        'page_title': 'YOLOç—…å®³æ£€æµ‹',
        'header_title': 'é±¼ç±»å¯„ç”Ÿè™«ç—…æ£€æµ‹',
        'header_subtitle': 'å›¾ç‰‡ / æ‰¹é‡ / è§†é¢‘ / æ‘„åƒå¤´ / è½¨è¿¹è·Ÿè¸ª / æ¨¡ç³Šé¢„æµ‹ â€” ä¸€ç«™å¼æ£€æµ‹å°',
        'sidebar_university': 'å®æ³¢å¤§å­¦ Â· ç—…å®³å®éªŒå®¤',
        'sidebar_model': 'ğŸ§  æ¨¡å‹ä¸å‚æ•°',
        'sidebar_model_type': 'æ¨¡å‹ç±»å‹',
        'sidebar_current_model': 'å½“å‰æ¨¡å‹:',
        'tab_image': 'ğŸ–¼ï¸ å›¾ç‰‡æ£€æµ‹',
        'tab_batch': 'ğŸ—‚ï¸ æ‰¹é‡å›¾ç‰‡',
        'tab_video': 'ğŸï¸ è§†é¢‘æ£€æµ‹',
        'tab_camera': 'ğŸ“· æ‘„åƒå¤´æ£€æµ‹',
        'tab_fuzzy': 'ğŸ§® æ¨¡ç³Šé¢„æµ‹',
        'image_original': 'åŸå›¾',
        'image_detection': 'æ£€æµ‹ä¸ç»“æœ',
        'image_upload': 'ä¸Šä¼ å›¾ç‰‡',
        'image_run': 'ğŸš€ å¼€å§‹æ£€æµ‹',
        'image_result': 'æ£€æµ‹ç»“æœ',
        'image_download_excel': 'ä¸‹è½½ Excelï¼ˆæ£€æµ‹è¡¨ï¼‰',
        'image_download_img': 'ä¸‹è½½ æ ‡æ³¨å›¾ç‰‡',
        'batch_upload': 'é€‰æ‹©å¤šå¼ å›¾ç‰‡',
        'batch_run': 'ğŸš€ å¼€å§‹æ‰¹é‡æ£€æµ‹',
        'batch_processing': 'æ¨ç†ä¸­ï¼š',
        'batch_total': 'æ€»æ•°ï¼š',
        'batch_no_results': 'æœªæ£€æµ‹åˆ°ç›®æ ‡ã€‚',
        'batch_download_excel': 'ğŸ“¥ ä¸‹è½½ Excelï¼ˆæ‰¹é‡æ£€æµ‹è¡¨ï¼‰',
        'batch_download_zip': 'ğŸ—œï¸ æ‰“åŒ…ä¸‹è½½ æ ‡æ³¨å›¾ç‰‡ZIP',
        'video_upload': 'ä¸Šä¼ è§†é¢‘',
        'video_run': 'ğŸš€ å¼€å§‹è§†é¢‘æ£€æµ‹',
        'video_disabled': 'å½“å‰äº‘ç«¯ç¯å¢ƒæœªèƒ½åŠ è½½ OpenCVï¼ˆcv2ï¼‰ï¼Œè§†é¢‘å¤„ç†åŠŸèƒ½å·²ç¦ç”¨ã€‚è¯·åœ¨æœ¬åœ°è¿è¡Œæˆ–å®‰è£…æ”¯æŒçš„ OpenCV ç‰ˆæœ¬ã€‚',
        'video_processing': 'æœ¬åœ°è§†é¢‘å¤„ç†...ï¼ˆæŒ‰ CPU é€Ÿåº¦å¯èƒ½è¾ƒæ…¢ï¼‰',
        'video_download': 'ä¸‹è½½å¤„ç†åè§†é¢‘',
        'camera_title': 'ğŸ“· æ‘„åƒå¤´æ£€æµ‹ï¼ˆæ‹ç…§ç‰ˆï¼‰',
        'camera_caption': 'ç‚¹å‡»â€œæ‰“å¼€æ‘„åƒå¤´â€åæ‰æ¸²æŸ“æ‹ç…§æ§ä»¶ï¼›ç‚¹å‡»â€œå…³é—­æ‘„åƒå¤´â€åœæ­¢å¹¶éšè—ã€‚',
        'camera_open': 'ğŸ¬ æ‰“å¼€æ‘„åƒå¤´',
        'camera_close': 'â¹ å…³é—­æ‘„åƒå¤´',
        'camera_not_started': 'æ‘„åƒå¤´æœªå¼€å¯ã€‚ç‚¹å‡»â€œæ‰“å¼€æ‘„åƒå¤´â€å¼€å§‹æ‹ç…§ã€‚',
        'camera_shot': 'ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®æ‹ä¸€å¼ ',
        'camera_detect': 'æ£€æµ‹æ­¤ç…§ç‰‡',
        'fuzzy_title': 'ğŸ§® æ¨¡ç³Šé¢„æµ‹',
        'fuzzy_input': 'è¾“å…¥æŒ‡æ ‡å‚æ•°',
        'fuzzy_day': 'æ—¥é—´è¡Œä¸ºï¼ˆ1~3ï¼‰',
        'fuzzy_night': 'å¤œé—´è¡Œä¸ºï¼ˆ1~3ï¼‰',
        'fuzzy_surface': 'ä½“è¡¨ç‰¹å¾ï¼ˆ1~3ï¼‰',
        'fuzzy_pathogen': 'ç—…åŸç‰¹å¾ï¼ˆ1~3ï¼‰',
        'fuzzy_predict': 'ğŸ§ª é¢„æµ‹',
        'fuzzy_result': 'é£é™©å€¼: {risk_value}ï¼ŒçŠ¶æ€: {risk_status}',
        'Ich': 'å¤šå­å°ç“œè™«ç—…',
        'Tomont': 'åŒ…å›Š',
        'healthy': 'å¥åº·',
        'subhealthy': 'äºšå¥åº·',
        'diseased': 'æ‚£ç—…',
        'category': 'ç±»åˆ«',
        'confidence': 'ç½®ä¿¡åº¦',
        'location': 'ä½ç½®',
        'path': 'è·¯å¾„',
        'model_not_found': 'æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{p}ï¼ˆ{k}æ¨¡å‹ï¼‰',
        'model_loaded': 'æˆåŠŸåŠ è½½æ¨¡å‹ï¼š{k} -> {p}'
    },
    'en': {
        # åŸæœ‰ç¿»è¯‘ä¿ç•™ï¼Œæ–°å¢ä»¥ä¸‹å­—æ®µ
        'tab_tracking': 'ğŸ“ Trajectory Tracking',
        'tracking_title': 'Goldfish Motion Trajectory Analysis',
        'tracking_upload': 'Upload Video File',
        'tracking_run': 'ğŸš€ Start Trajectory Analysis',
        'tracking_processing': 'Analyzing video trajectory...',
        'total_distance': 'Total Distance (pixels)',
        'average_speed': 'Average Movement Speed (pixels/sec)',
        'video_duration': 'Video Duration (sec)',
        'total_frames': 'Total Frames',
        'no_fish_detected': 'No goldfish detected, cannot calculate trajectory data',
        # åŸæœ‰ç¿»è¯‘
        'page_title': 'YOLO Disease Detection',
        'header_title': 'Fish Parasitic Disease Detection',
        'header_subtitle': 'Image / Batch / Video / Camera / Trajectory Tracking / Fuzzy Prediction â€” One-stop Detection Platform',
        'sidebar_university': 'Ningbo University Â· Disease Laboratory',
        'sidebar_model': 'ğŸ§  Model & Parameters',
        'sidebar_model_type': 'Model Type',
        'sidebar_current_model': 'Current Model:',
        'tab_image': 'ğŸ–¼ï¸ Image Detection',
        'tab_batch': 'ğŸ—‚ï¸ Batch Images',
        'tab_video': 'ğŸï¸ Video Detection',
        'tab_camera': 'ğŸ“· Camera Detection',
        'tab_fuzzy': 'ğŸ§® Fuzzy Prediction',
        'image_original': 'Original Image',
        'image_detection': 'Detection & Results',
        'image_upload': 'Upload Image',
        'image_run': 'ğŸš€ Start Detection',
        'image_result': 'Detection Result',
        'image_download_excel': 'Download Excel (Detection Table)',
        'image_download_img': 'Download Annotated Image',
        'batch_upload': 'Select Multiple Images',
        'batch_run': 'ğŸš€ Start Batch Detection',
        'batch_processing': 'Processing: ',
        'batch_total': 'Total: ',
        'batch_no_results': 'No targets detected.',
        'batch_download_excel': 'ğŸ“¥ Download Excel (Batch Detection)',
        'batch_download_zip': 'ğŸ—œï¸ Download Annotated Images (ZIP)',
        'video_upload': 'Upload Video',
        'video_run': 'ğŸš€ Start Video Detection',
        'video_disabled': 'OpenCV (cv2) not loaded in current cloud environment. Video processing disabled. Please run locally or install supported OpenCV version.',
        'video_processing': 'Local video processing... (May be slow depending on CPU)',
        'video_download': 'Download Processed Video',
        'camera_title': 'ğŸ“· Camera Detection (Photo Mode)',
        'camera_caption': 'Camera widget loads only after clicking "Open Camera"; click "Close Camera" to stop and hide.',
        'camera_open': 'ğŸ¬ Open Camera',
        'camera_close': 'â¹ Close Camera',
        'camera_not_started': 'Camera not started. Click "Open Camera" to begin.',
        'camera_shot': 'Click button below to take photo',
        'camera_detect': 'Detect This Photo',
        'fuzzy_title': 'ğŸ§® Fuzzy Prediction',
        'fuzzy_input': 'Input Indicator Parameters',
        'fuzzy_day': 'Day Behavior (1~3)',
        'fuzzy_night': 'Night Behavior (1~3)',
        'fuzzy_surface': 'Surface Features (1~3)',
        'fuzzy_pathogen': 'Pathogen Features (1~3)',
        'fuzzy_predict': 'ğŸ§ª Predict',
        'fuzzy_result': 'Risk Value: {risk_value}, Status: {risk_status}',
        'Ich': 'Ichthyophthirius Disease',
        'Tomont': 'Tomont',
        'healthy': 'Healthy',
        'subhealthy': 'Subhealthy',
        'diseased': 'Diseased',
        'category': 'Category',
        'confidence': 'Confidence',
        'location': 'Location',
        'path': 'Path',
        'model_not_found': 'Model file not found: {p} ({k} model)',
        'model_loaded': 'Successfully loaded model: {k} -> {p}'
    }
}

# è·å–å½“å‰è¯­è¨€ç¿»è¯‘
def t(key):
    return translations[st.session_state.language].get(key, key)

# ====================== é¡µé¢é…ç½® ======================
st.set_page_config(page_title=t('page_title'), page_icon="ğŸ§ª", layout="wide")

# ====================== æ¨¡å‹åŠ è½½ ======================
BASE_DIR = Path(__file__).parent
WEIGHTS = BASE_DIR / "best.pt"  # Ichæ¨¡å‹
TOMONT_WEIGHTS = BASE_DIR / "tomont.best.pt"  # æ–°å¢Tomontæ¨¡å‹è·¯å¾„
IMG_DIR = BASE_DIR / "img"
MODEL_PATHS = {"Ich": str(WEIGHTS), "Tomont": str(TOMONT_WEIGHTS)}  # ç§»é™¤Lycï¼Œåˆ†åˆ«å¯¹åº”ä¸åŒæ¨¡å‹
DEFAULT_CONF = 0.6  # é»˜è®¤ç½®ä¿¡åº¦

@st.cache_resource
def load_models():
    models = {}
    for k, p in MODEL_PATHS.items():
        if not Path(p).exists():
            st.error(t('model_not_found').format(p=p, k=k))
        else:
            models[k] = YOLO(p)
            st.success(t('model_loaded').format(k=k, p=p))
    return models

MODELS = load_models()

# ====================== æ ¸å¿ƒå·¥å…·å‡½æ•° ======================
def detections_to_df(res) -> pd.DataFrame:
    if hasattr(res, "boxes") and hasattr(res, "names"):
        rows = []
        names = getattr(res, "names", {}) or {}
        boxes = getattr(res, "boxes", None)
        if boxes is not None and len(boxes) > 0:
            cls_np  = boxes.cls.detach().cpu().numpy().astype(int)
            conf_np = boxes.conf.detach().cpu().numpy()
            xyxy_np = boxes.xyxy.detach().cpu().numpy()
            for i in range(len(cls_np)):
                rows.append({
                    t("category"): names.get(int(cls_np[i]), str(int(cls_np[i]))),
                    t("confidence"): float(conf_np[i]),
                    t("location"): [float(x) for x in xyxy_np[i].tolist()],
                })
        return pd.DataFrame(rows)
    if isinstance(res, list):
        rows = []
        for d in res or []:
            rows.append({
                t("category"): d.get("category") or d.get("class_name") or d.get("name") or d.get("cls"),
                t("confidence"): d.get("conf") or d.get("confidence"),
                t("location"): d.get("location") or d.get("bbox") or d.get("xyxy"),
                t("path"): d.get("path"),
            })
        return pd.DataFrame(rows)
    if isinstance(res, pd.DataFrame):
        return res
    return pd.DataFrame()

def predict_on_image(img_input, model_key: str, conf: float | None = None):
    if isinstance(img_input, (bytes, bytearray)):
        pil_img = Image.open(io.BytesIO(img_input)).convert("RGB")
    elif isinstance(img_input, Image.Image):
        pil_img = img_input.convert("RGB")
    elif isinstance(img_input, (str, Path)):
        pil_img = Image.open(img_input).convert("RGB")
    elif isinstance(img_input, np.ndarray):
        if img_input.ndim == 2:
            pil_img = Image.fromarray(img_input)
        elif img_input.ndim == 3:
            if CV2_OK:
                pil_img = Image.fromarray(cv2.cvtColor(img_input, cv2.COLOR_BGR2RGB))
            else:
                pil_img = Image.fromarray(img_input[..., ::-1])
        else:
            raise TypeError(f"Unsupported numpy shape: {img_input.shape}")
    else:
        raise TypeError(f"Unsupported type: {type(img_input)}")

    c = float(conf) if conf is not None else DEFAULT_CONF
    r = MODELS[model_key].predict(source=pil_img, conf=c, imgsz=640, verbose=False)[0]
    im_bgr = r.plot()
    im_rgb = im_bgr[..., ::-1]
    vis_pil = Image.fromarray(im_rgb)
    df = detections_to_df(r)
    return vis_pil, df

# åŸæœ‰è§†é¢‘å¤„ç†å‡½æ•°ï¼ˆä¿ç•™ï¼Œä¾›è§†é¢‘æ£€æµ‹æ ‡ç­¾é¡µä½¿ç”¨ï¼‰
def process_video(video_bytes: bytes, model_key: str, conf: float | None = None, max_frames: int | None = None) -> Path:
    if not CV2_OK:
        raise RuntimeError(t("video_disabled"))
    in_path = Path("input_tmp.mp4"); in_path.write_bytes(video_bytes)
    cap = cv2.VideoCapture(str(in_path))
    if not cap.isOpened(): raise RuntimeError("æ— æ³•è¯»å–è§†é¢‘" if st.session_state.language == 'zh' else "Cannot read video")

    fps = cap.get(cv2.CAP_PROP_FPS) or 25
    w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    out_path = Path(f"processed_{int(time.time())}.mp4")
    vw = cv2.VideoWriter(str(out_path), cv2.VideoWriter_fourcc(*"mp4v"), fps, (w, h))

    i = 0
    while True:
        ok, frame = cap.read()
        if not ok: break
        i += 1
        if max_frames and i > max_frames: break
        c = float(conf) if conf is not None else DEFAULT_CONF
        r = MODELS[model_key].predict(source=frame, conf=c, imgsz=640, verbose=False)[0]
        vw.write(r.plot())

    cap.release(); vw.release()
    return out_path

# æ–°å¢ï¼šè½¨è¿¹åˆ†ææ ¸å¿ƒå‡½æ•°
def calculate_fish_trajectory(video_bytes: bytes, model_key: str, conf: float = DEFAULT_CONF, max_frames: int = None) -> dict:
    """
    åˆ†æè§†é¢‘ä¸­é‡‘é±¼çš„è¿åŠ¨è½¨è¿¹ï¼Œè¿”å›ç»Ÿè®¡ç»“æœ
    è¿”å›å€¼ï¼š{
        "total_distance": æ€»è·¯ç¨‹(åƒç´ ),
        "average_speed": å¹³å‡é€Ÿåº¦(åƒç´ /ç§’),
        "video_duration": è§†é¢‘æ—¶é•¿(ç§’),
        "total_frames": æ€»å¸§æ•°,
        "success": æ˜¯å¦æˆåŠŸ,
        "message": æç¤ºä¿¡æ¯
    }
    """
    if not CV2_OK:
        return {
            "success": False,
            "message": t("video_disabled"),
            "total_distance": 0,
            "average_speed": 0,
            "video_duration": 0,
            "total_frames": 0
        }
    
    # åˆå§‹åŒ–å˜é‡
    prev_center = None  # ä¸Šä¸€å¸§é‡‘é±¼ä¸­å¿ƒåæ ‡
    total_distance = 0.0  # æ€»è·¯ç¨‹
    total_frames = 0  # æ€»å¸§æ•°
    # å®šä¹‰é‡‘é±¼ç±»åˆ«ï¼ˆæ’é™¤åŒ…å›Šï¼‰
    fish_categories = {t("healthy"), t("subhealthy"), t("diseased"), "å¥åº·", "äºšå¥åº·", "æ‚£ç—…", "Healthy", "Subhealthy", "Diseased"}
    
    # å†™å…¥ä¸´æ—¶è§†é¢‘æ–‡ä»¶
    in_path = Path("traj_input_tmp.mp4")
    in_path.write_bytes(video_bytes)
    
    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(str(in_path))
    if not cap.isOpened():
        return {
            "success": False,
            "message": "æ— æ³•è¯»å–è§†é¢‘æ–‡ä»¶" if st.session_state.language == 'zh' else "Cannot read video file",
            "total_distance": 0,
            "average_speed": 0,
            "video_duration": 0,
            "total_frames": 0
        }
    
    # è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0  # è§†é¢‘å¸§ç‡
    total_frames_total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # è§†é¢‘æ€»å¸§æ•°
    
    # é€å¸§å¤„ç†
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        total_frames += 1
        
        # é™åˆ¶æœ€å¤§å¸§æ•°ï¼ˆé˜²æ­¢è¶…é•¿è§†é¢‘å¡é¡¿ï¼‰
        if max_frames and total_frames > max_frames:
            break
        
        # æ›´æ–°è¿›åº¦
        progress = min(total_frames / total_frames_total, 1.0)
        progress_bar.progress(progress)
        status_text.text(f"{t('tracking_processing')} {total_frames}/{total_frames_total}")
        
        # æ¨¡å‹æ¨ç†
        try:
            r = MODELS[model_key].predict(source=frame, conf=conf, imgsz=640, verbose=False)[0]
        except Exception as e:
            status_text.empty()
            progress_bar.empty()
            cap.release()
            in_path.unlink(missing_ok=True)
            return {
                "success": False,
                "message": f"å¸§æ¨ç†å¤±è´¥: {str(e)}",
                "total_distance": 0,
                "average_speed": 0,
                "video_duration": 0,
                "total_frames": total_frames
            }
        
        # æå–å½“å‰å¸§é‡‘é±¼çš„ä¸­å¿ƒåæ ‡ï¼ˆå–ç½®ä¿¡åº¦æœ€é«˜çš„ï¼‰
        current_center = None
        max_conf = 0.0
        if hasattr(r, "boxes") and len(r.boxes) > 0:
            for box in r.boxes:
                cls_idx = int(box.cls.item())
                cls_name = r.names.get(cls_idx, "")
                # è¿‡æ»¤å‡ºé‡‘é±¼ç±»åˆ«
                if cls_name in fish_categories:
                    conf_score = float(box.conf.item())
                    if conf_score > max_conf:
                        max_conf = conf_score
                        # è®¡ç®—æ£€æµ‹æ¡†ä¸­å¿ƒåæ ‡
                        xyxy = box.xyxy.cpu().numpy()[0]  # [x1, y1, x2, y2]
                        center_x = (xyxy[0] + xyxy[2]) / 2
                        center_y = (xyxy[1] + xyxy[3]) / 2
                        current_center = (center_x, center_y)
        
        # è®¡ç®—ä¸ä¸Šä¸€å¸§çš„è·ç¦»
        if prev_center is not None and current_center is not None:
            # æ¬§æ°è·ç¦»å…¬å¼ï¼šâˆš[(x2-x1)Â² + (y2-y1)Â²]
            distance = math.hypot(current_center[0] - prev_center[0], current_center[1] - prev_center[1])
            total_distance += distance
        
        # æ›´æ–°ä¸Šä¸€å¸§åæ ‡
        if current_center is not None:
            prev_center = current_center
    
    # æ¸…ç†èµ„æº
    cap.release()
    in_path.unlink(missing_ok=True)
    progress_bar.empty()
    status_text.empty()
    
    # è®¡ç®—è§†é¢‘æ—¶é•¿å’Œå¹³å‡é€Ÿåº¦
    video_duration = total_frames / fps if fps > 0 else 0
    average_speed = total_distance / video_duration if video_duration > 0 else 0
    
    # æ£€æµ‹æ˜¯å¦æœ‰æœ‰æ•ˆè½¨è¿¹
    if total_distance == 0:
        return {
            "success": True,
            "message": t("no_fish_detected"),
            "total_distance": 0,
            "average_speed": 0,
            "video_duration": round(video_duration, 2),
            "total_frames": total_frames
        }
    
    return {
        "success": True,
        "message": "è½¨è¿¹åˆ†æå®Œæˆ",
        "total_distance": round(total_distance, 2),
        "average_speed": round(average_speed, 2),
        "video_duration": round(video_duration, 2),
        "total_frames": total_frames
    }

def save_table_to_excel(df: pd.DataFrame, filename: str) -> Path:
    out = Path(filename).with_suffix(".xlsx")
    with pd.ExcelWriter(out, engine="xlsxwriter") as w:
        df.to_excel(w, sheet_name="detections" if st.session_state.language == 'zh' else "Detections", index=False)
    return out

def zip_files(files: list[Path], out_zip: Path) -> Path:
    with zipfile.ZipFile(out_zip, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        for f in files:
            if f.exists(): zf.write(f, arcname=f.name)
    return out_zip

# ========= æ¨¡ç³Šé¢„æµ‹ =========
@st.cache_resource
def build_fuzzy_sim():
    day = ctrl.Antecedent(np.arange(1, 4.1, 0.1), 'day')
    night = ctrl.Antecedent(np.arange(1, 4.1, 0.1), 'night')
    surf = ctrl.Antecedent(np.arange(1, 4.1, 0.1), 'surf')
    patho = ctrl.Antecedent(np.arange(1, 4.1, 0.1), 'patho')
    risk = ctrl.Consequent(np.arange(0, 4.1, 0.1), 'risk')

    for b in [day, night]:
        b['healthy'] = fuzz.trimf(b.universe, [1, 1, 1.5])
        b['subhealthy'] = fuzz.trimf(b.universe, [1.5, 2, 2.5])
        b['diseased'] = fuzz.trimf(b.universe, [2.5, 3, 4])

    surf['healthy'] = fuzz.trimf(surf.universe, [1, 1, 2])
    surf['diseased'] = fuzz.trimf(surf.universe, [2, 3, 4])
    patho['absent'] = fuzz.trimf(patho.universe, [1, 1, 2])
    patho['present'] = fuzz.trimf(patho.universe, [2, 3, 4])

    risk['health'] = fuzz.trimf(risk.universe, [0, 1, 1.5])
    risk['subhealth'] = fuzz.trimf(risk.universe, [1.5, 2, 2.5])
    risk['diseased'] = fuzz.trimf(risk.universe, [2.5, 3, 4])
    risk.defuzzify_method = 'centroid'

    rules = [
        ctrl.Rule(day['subhealthy'] & night['diseased'] & surf['healthy'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['healthy'] & night['healthy'] & surf['healthy'] & patho['absent'], risk['health']),
        ctrl.Rule(day['diseased'] | night['diseased'], risk['diseased']),
        ctrl.Rule(day['subhealthy'] | night['subhealthy'], risk['subhealth']),
        ctrl.Rule(surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(surf['healthy'] & patho['absent'], risk['health']),
        ctrl.Rule(day['healthy'] & night['subhealthy'] & surf['healthy'] & patho['present'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['healthy'] & surf['healthy'] & patho['present'], risk['subhealth']),
        ctrl.Rule(day['healthy'] & night['healthy'] & surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['healthy'] & night['healthy'] & surf['healthy'] & patho['present'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['subhealthy'] & surf['healthy'] & patho['absent'], risk['health']),
        ctrl.Rule(day['subhealthy'] & night['subhealthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['diseased'] & surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['diseased'] & night['subhealthy'] & surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['subhealthy'] & night['subhealthy'] & surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['healthy'] & night['subhealthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['healthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['subhealthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['healthy'] & night['healthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['diseased'] & night['diseased'] & surf['healthy'] & patho['absent'], risk['diseased']),
        ctrl.Rule(day['diseased'] & night['diseased'] & surf['diseased'] & patho['absent'], risk['diseased']),
        ctrl.Rule(day['diseased'] & night['diseased'] & surf['healthy'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['diseased'] & night['diseased'] & surf['diseased'] & patho['present'], risk['diseased']),
    ]
    for r in rules: r.weight = 1.0
    rules[4].weight = 2; rules[5].weight = 2

    return ctrl.ControlSystemSimulation(ctrl.ControlSystem(rules))

def fuzzy_predict(day_val: float, night_val: float, surf_val: float, patho_val: float) -> dict:
    sim = build_fuzzy_sim()
    sim.input['day'] = day_val
    sim.input['night'] = night_val
    sim.input['surf'] = surf_val
    sim.input['patho'] = patho_val
    sim.compute()
    v = float(sim.output['risk'])
    if st.session_state.language == 'zh':
        status = "å¥åº·" if v < 1.5 else ("äºšå¥åº·" if v < 2.5 else "æ‚£ç—…")
    else:
        status = t("healthy") if v < 1.5 else (t("subhealthy") if v < 2.5 else t("diseased"))
    return {"risk_value": round(v, 1), "risk_status": status}

# ========================= å…¨å±€æ ·å¼ =========================
st.markdown("""
<style>
.app-header {
  background: linear-gradient(90deg, #4F46E5 0%, #7C3AED 100%);
  color: white; border-radius: 16px; padding: 16px 20px; margin-bottom: 12px;
  display:flex; align-items:center; gap:14px;
}
.app-title { font-size: 22px; font-weight: 700; letter-spacing:.3px; }
.app-subtitle { opacity:.9; font-size: 13px; }

.note {
  background:#EEF2FF; border:1px solid #E0E7FF; color:#3730A3;
  border-radius: 12px; padding: 10px 12px; margin: 6px 0 16px 0; font-size:13px;
}

.card {
  background: var(--secondary-bg, #F6F7FB);
  border: 1px solid #E5E7EB;
  border-radius: 14px;
  padding: 14px;
  margin-bottom: 12px;
}

:root { --secondary-bg: #F6F7FB; }
[data-base-theme="light"] :root { --secondary-bg: #F6F7FB; }
[data-base-theme="dark"]  :root { --secondary-bg: #111827; }

[data-testid="stDataFrame"] { border-radius: 12px; overflow:hidden; }

.stButton>button { border-radius: 10px; }
.block-container { padding-top: 0.6rem; padding-bottom: 1rem; }

.badge {
  display: inline-flex; align-items: center; gap: 6px;
  background: #EEF2FF; color:#3730A3; border:1px solid #E0E7FF;
  padding: 4px 8px; border-radius: 999px; font-size: 12px; font-weight:600;
}

/* è¯­è¨€åˆ‡æ¢æŒ‰é’®æ ·å¼ */
.lang-switch {
  position: fixed;
  top: 20px;
  right: 20px;
  z-index: 999;
}

/* è½¨è¿¹ç»Ÿè®¡å¡ç‰‡æ ·å¼ */
.traj-card {
  background: #f0f8ff;
  border: 1px solid #b8d4ff;
  border-radius: 12px;
  padding: 16px;
  margin: 8px 0;
}
.traj-metric {
  font-size: 18px;
  font-weight: 600;
  color: #2563eb;
}
</style>
""", unsafe_allow_html=True)

# éšè—Streamlité»˜è®¤ç»„ä»¶
st.markdown("""
<style>
header[data-testid="stHeader"] {visibility: hidden;}
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
[data-testid="stAppViewContainer"] .main .block-container { padding-top: 0.8rem !important; }
.app-header { margin-top: 4px; }
#svc-config { display: none !important; }
</style>
""", unsafe_allow_html=True)

# è¯­è¨€åˆ‡æ¢æŒ‰é’®
with st.sidebar:
    lang_col1, lang_col2 = st.columns(2)
    with lang_col1:
        if st.button('ä¸­æ–‡', use_container_width=True):
            st.session_state.language = 'zh'
            st.rerun()
    with lang_col2:
        if st.button('English', use_container_width=True):
            st.session_state.language = 'en'
            st.rerun()

# é¡¶éƒ¨å¯¼èˆªæ¡
st.markdown(f"""
<style>
.app-header {{
  background: linear-gradient(90deg, #4F46E5 0%, #7C3AED 100%);
  color: white;
  border-radius: 14px;
  padding: 14px 18px;
  margin-bottom: 14px;
  text-align: center;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
}}
.app-title-row {{
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 12px;
  margin-bottom: 8px;
}}
.app-icon {{
  font-size: 42px;
}}
.app-title {{
  font-size: 36px;
  font-weight: 800;
  letter-spacing: 1px;
}}
.app-subtitle {{
  font-size: 20px;
  opacity: 0.95;
}}
</style>
<div class="app-header">
  <div class="app-title-row">
    <div class="app-icon">ğŸ§ª</div>
    <div class="app-title">{t('header_title')}</div>
  </div>
  <div class="app-subtitle">{t('header_subtitle')}</div>
</div>
""", unsafe_allow_html=True)

# ä¾§è¾¹æ 
with st.sidebar:
    st.markdown(f"### ğŸ“ {t('sidebar_university')}")
    st.markdown('<div id="svc-config">', unsafe_allow_html=True)
    base_url = "http://localhost:8080"
    ws_url_override = base_url.replace("http://", "ws://").replace("https://", "wss://")
    st.divider()
    st.header(t('sidebar_model'))
    model_options = {"Ich": t('Ich'), "Tomont": t('Tomont')}
    model_value = st.selectbox(t('sidebar_model_type'), options=list(model_options.keys()),
                               format_func=lambda x: f"{x}ï¼ˆ{model_options[x]}ï¼‰")
    st.markdown(f"<span class='badge'>{t('sidebar_current_model')} <b>{model_value}</b></span>", unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)

# ========================= æ ‡ç­¾é¡µï¼ˆæ–°å¢è½¨è¿¹è·Ÿè¸ªæ ‡ç­¾ï¼‰ =========================
# ä¿®æ”¹æ ‡ç­¾é¡µå®šä¹‰ï¼ŒåŠ å…¥è½¨è¿¹è·Ÿè¸ª
tab_img, tab_folder, tab_video, tab_camera, tab_tracking, tab_fuzzy = st.tabs([
    t('tab_image'), 
    t('tab_batch'), 
    t('tab_video'), 
    t('tab_camera'), 
    t('tab_tracking'),  # æ–°å¢ï¼šè½¨è¿¹è·Ÿè¸ªæ ‡ç­¾é¡µ
    t('tab_fuzzy')
])

# -------------------------------- 1) å›¾ç‰‡æ£€æµ‹ --------------------------------
with tab_img:
    st.markdown(f"#### {t('tab_image')}")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f"<div class='card'><b>{t('image_original')}</b></div>", unsafe_allow_html=True)
        img_file = st.file_uploader(t('image_upload'), type=["jpg","jpeg","png","bmp","webp"], key="single_img_main")
        if img_file:
            st.image(Image.open(img_file), caption=t('image_original'), use_column_width=True)
    with col2:
        st.markdown(f"<div class='card'><b>{t('image_detection')}</b></div>", unsafe_allow_html=True)
        run_single = st.button(t('image_run'), type="primary", use_container_width=True, disabled=img_file is None)
        if run_single and img_file:
            with st.spinner("æœ¬åœ°æ¨¡å‹æ¨ç†ä¸­..." if st.session_state.language == 'zh' else "Local model inferencing..."):
                det_img, df = predict_on_image(img_file.getvalue(), model_value)
            st.image(det_img, caption=t('image_result'), use_column_width=True)
            if not df.empty:
                st.dataframe(df, use_container_width=True)
                c1, c2 = st.columns(2)
                with c1:
                    if st.button(t('image_download_excel'), use_container_width=True):
                        xlsx_path = save_table_to_excel(df, "image_detect_result.xlsx")
                        st.download_button(t('image_download_excel'), data=open(xlsx_path, "rb").read(),
                                           file_name=xlsx_path.name,
                                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
                with c2:
                    if st.button(t('image_download_img'), use_container_width=True):
                        bio = io.BytesIO();
                        det_img.save(bio, format="JPEG")
                        st.download_button(t('image_download_img'), data=bio.getvalue(), file_name="image_detect_result.jpg",
                                           mime="image/jpeg")

# ----------------------------- 2) æ‰¹é‡å›¾ç‰‡æ£€æµ‹ -----------------------------
with tab_folder:
    st.markdown(f"#### {t('tab_batch')}")
    files = st.file_uploader(
        t('batch_upload'),
        type=["jpg", "jpeg", "png", "bmp", "webp"],
        accept_multiple_files=True,
        key="multi_imgs",
    )
    go = st.button(t('batch_run'), type="primary", disabled=not files)
    if go and files:
        all_tables: List[pd.DataFrame] = []
        out_imgs: List[Path] = []
        progress = st.progress(0)
        status = st.empty()
        total = len(files)
        for i, f in enumerate(files, start=1):
            status.info(f"{t('batch_processing')}{f.name} ({i}/{total})")
            with st.spinner(f"{t('batch_processing')}{f.name}"):
                det_img, df = predict_on_image(f.getvalue(), model_value)
                if not df.empty:
                    df[t("path")] = f.name
                    all_tables.append(df)
                out_path = Path(f"{Path(f.name).stem}_detect.jpg")
                det_img.save(out_path)
                out_imgs.append(out_path)
            progress.progress(i / total)
        df_all = pd.concat(all_tables, ignore_index=True) if all_tables else pd.DataFrame()
        if not df_all.empty:
            st.dataframe(df_all, use_container_width=True)
            xlsx_path = save_table_to_excel(df_all, "batch_detect.xlsx")
            st.download_button(
                t('batch_download_excel'),
                data=open(xlsx_path, "rb").read(),
                file_name=xlsx_path.name,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
            )
        else:
            st.info(t('batch_no_results'))
        if out_imgs:
            zpath = zip_files(out_imgs, Path("batch_detect_images.zip"))
            st.download_button(
                t('batch_download_zip'),
                data=open(zpath, "rb").read(),
                file_name=zpath.name,
                mime="application/zip",
                use_container_width=True,
            )
        status.empty()
        progress.empty()

# -------------------------------- 3) è§†é¢‘æ£€æµ‹ --------------------------------
with tab_video:
    st.markdown(f"#### {t('tab_video')}")
    vid_file = st.file_uploader(
        t('video_upload'), type=["mp4", "mov", "avi", "mkv"], key="video_file"
    )
    run_vid = st.button(t('video_run'), type="primary", disabled=(vid_file is None or not CV2_OK))
    if not CV2_OK:
        st.warning(t('video_disabled'))
    if run_vid and vid_file:
        with st.spinner(t('video_processing')):
            out_path = process_video(vid_file.getvalue(), model_value, max_frames=None)
        st.video(str(out_path))
        st.download_button(
            t('video_download'),
            data=open(out_path, "rb").read(),
            file_name=out_path.name,
            mime="video/mp4",
        )

# -------------------------- 4) æ‘„åƒå¤´æ£€æµ‹ --------------------------
with tab_camera:
    st.markdown(f"#### {t('camera_title')}")
    st.caption(t('camera_caption'))
    if "cam_on" not in st.session_state:
        st.session_state.cam_on = False
    col_a, col_b = st.columns(2)
    if not st.session_state.cam_on:
        if col_a.button(t('camera_open'), type="primary"):
            st.session_state.cam_on = True
            st.rerun()
        col_b.button(t('camera_close'), disabled=True)
        st.info(t('camera_not_started'))
    else:
        if col_b.button(t('camera_close'), type="secondary"):
            st.session_state.cam_on = False
            st.rerun()
        col_a.button(t('camera_open'), disabled=True)
        snap = st.camera_input(t('camera_shot'), key="cam_shot")
        go = st.button(t('camera_detect'), type="primary", disabled=(snap is None))
        if go and snap is not None:
            with st.spinner("æœ¬åœ°æ¨¡å‹æ¨ç†ä¸­..." if st.session_state.language == 'zh' else "Local model inferencing..."):
                det_img, df = predict_on_image(snap.getvalue(), model_value)
            st.image(det_img, caption=t('image_result'), use_column_width=True)
            if not df.empty:
                st.dataframe(df, use_container_width=True)

# -------------------------- 5) è½¨è¿¹è·Ÿè¸ªï¼ˆæ–°å¢ï¼‰ --------------------------
with tab_tracking:
    st.markdown(f"#### {t('tracking_title')}")
    
    # è§†é¢‘ä¸Šä¼ 
    vid_file = st.file_uploader(
        t('tracking_upload'),
        type=["mp4", "mov", "avi", "mkv"],
        key="tracking_video_file",
        help="æ”¯æŒå¸¸è§è§†é¢‘æ ¼å¼ï¼Œå»ºè®®æ—¶é•¿ä¸è¶…è¿‡1åˆ†é’Ÿä»¥ä¿è¯åˆ†æé€Ÿåº¦"
    )
    
    # ç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®
    conf_threshold = st.slider(
        "æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼",
        min_value=0.1,
        max_value=1.0,
        value=DEFAULT_CONF,
        step=0.05,
        key="tracking_conf"
    )
    
    # æœ€å¤§å¸§æ•°é™åˆ¶ï¼ˆé˜²æ­¢è¶…é•¿è§†é¢‘å¡é¡¿ï¼‰
    max_frames = st.number_input(
        "æœ€å¤§åˆ†æå¸§æ•°ï¼ˆ0=æ— é™åˆ¶ï¼‰",
        min_value=0,
        max_value=10000,
        value=0,
        step=100,
        key="tracking_max_frames"
    )
    
    # å¼€å§‹åˆ†ææŒ‰é’®
    run_tracking = st.button(
        t('tracking_run'),
        type="primary",
        disabled=(vid_file is None or not CV2_OK),
        use_container_width=True
    )
    
    # CV2æœªåŠ è½½æç¤º
    if not CV2_OK:
        st.warning(t('video_disabled'))
    
    # æ‰§è¡Œè½¨è¿¹åˆ†æ
    if run_tracking and vid_file and CV2_OK:
        with st.spinner(t('tracking_processing')):
            # è°ƒç”¨è½¨è¿¹åˆ†æå‡½æ•°
            result = calculate_fish_trajectory(
                video_bytes=vid_file.getvalue(),
                model_key=model_value,
                conf=conf_threshold,
                max_frames=max_frames if max_frames > 0 else None
            )
        
        # å±•ç¤ºç»“æœ
        st.markdown("### ğŸ“Š åˆ†æç»“æœ")
        if result["success"]:
            # æˆåŠŸç»“æœå±•ç¤º
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.markdown(f"""
                <div class="traj-card">
                    <p>{t('total_distance')}</p>
                    <p class="traj-metric">{result['total_distance']}</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                st.markdown(f"""
                <div class="traj-card">
                    <p>{t('average_speed')}</p>
                    <p class="traj-metric">{result['average_speed']}</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                st.markdown(f"""
                <div class="traj-card">
                    <p>{t('video_duration')}</p>
                    <p class="traj-metric">{result['video_duration']}</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col4:
                st.markdown(f"""
                <div class="traj-card">
                    <p>{t('total_frames')}</p>
                    <p class="traj-metric">{result['total_frames']}</p>
                </div>
                """, unsafe_allow_html=True)
            
            # æç¤ºä¿¡æ¯
            if result["total_distance"] == 0:
                st.info(result["message"])
            else:
                st.success("è½¨è¿¹åˆ†æå®Œæˆï¼")
        
        else:
            # å¤±è´¥æç¤º
            st.error(f"åˆ†æå¤±è´¥ï¼š{result['message']}")

# -------------------------------- 6) æ¨¡ç³Šé¢„æµ‹ --------------------------------
with tab_fuzzy:
    st.markdown(f"#### {t('fuzzy_title')}")
    st.markdown(f"<div class='card'><b>{t('fuzzy_input')}</b></div>", unsafe_allow_html=True)
    c1, c2 = st.columns(2)
    with c1:
        day_behavior   = st.number_input(t('fuzzy_day'),  min_value=1.0, max_value=3.0, value=3.0, step=1.0)
        night_behavior = st.number_input(t('fuzzy_night'),  min_value=1.0, max_value=3.0, value=1.0, step=1.0)
    with c2:
        surface_features = st.number_input(t('fuzzy_surface'), min_value=1.0, max_value=3.0, value=3.0, step=1.0)
        pathogen         = st.number_input(t('fuzzy_pathogen'), min_value=1.0, max_value=3.0, value=3.0, step=1.0)
    if st.button(t('fuzzy_predict'), type="primary"):
        r = fuzzy_predict(day_behavior, night_behavior, surface_features, pathogen)
        st.success(t('fuzzy_result').format(risk_value=r['risk_value'], risk_status=r['risk_status']))
